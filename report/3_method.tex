
\subsection{Components}
Figure \ref{fig:overview} shows an overview of how the different components in the simulation are structured. We can see that a loader component unpacks a zip archive and passes each file as a record stream to a corresponding core in the system. Each core has one cache each and is connnected to the bus.

\begin{figure}[ht]
    \centering
    \incfig{overview}
    \caption{Overview}
    \label{fig:overview}
\end{figure}



\subsubsection{Record}

A record consists of a label and a value. 
During the initialization of the simulation, a loader unpacks the passed zip archive and converts each file contained in the zip archive to a record stream.
Given the following line in one such unpacked file
\begin{lstlisting}
0 0x817ae8
\end{lstlisting}
a record will be created in the following form
\begin{lstlisting}
Record {
    label: Label::Load,
    value: 0x817ae8
}
\end{lstlisting}


\subsubsection{System}
The system keeps the state of all the cores and make sure that each core is updated.
The system will create as many cores as needed to satisfy each file unpacked from the zip archive.
The update step for each core consists of three stages: \texttt{step}, \texttt{snoop} and \texttt{after\_snoop}.
The \texttt{step} stage parses the new instruction into a record and updates the state given the record.
The \texttt{snoop} stage will snoop the bus.
If the bus currently have an active task and the task's issuer is not the core that is snooping the core may update its state given the active task and current state for that cache line.
The \texttt{after\_snoop} stage is a cleanup stage done after the snooping stage.
It consists of changing the state of a cache line depending on the outcome of the snoop stage, that is, if it turns out that the cache line should be shared. 

\subsubsection{Core}
The core keeps the state of the cache and all the records.

\subsubsection{Cache}
The cache keeps the state of each cache line, the corresponding LRU value for each cache line, which protocol is in use, the scheduled instructions as well as the address layout of the cache.
When the cache is initialized in each core the address layout is calculated and consists of the offset length, the index length, the tag length, the set size and the block size.
The cache lines and LRU are both represented as a two dimensional vector containing an unsigned integer, where the rows represent the sets and the columns represent the blocks.
Note that there is no need to index the words directly as we load the whole block each time we access a word within the block.
The scheduled instructions are stored as a deque containing a tuple, the address and the action.
There are two valid actions a scheduled instruction can have, read and write.
Read operations are inserted at the front of the deque, while the write operations are inserted at the back of the deque.
Since the deque is processed from front to back, higher priority will be given to the read operations rather than the write operations.

The cache is updated at every step the core is updated.
During an update the cache first checks if there is an active task on the bus that does not belong to the core that is updating.
If that is not the case, the cache will return immediately, stalling the cache as the cache has to wait for its last task to finish.
Otherwise the cache will pop the front of the deque and try to do either an internal load or internal store depending on the action of the popped instruction.
An internal load will search for the given address to see if it is already present in the cache, a hit, and perform the neccesary steps to update the state for the cache line depending on which protocol which is in use.
If there is not cache hit, the cache will check if a writeback is needed given the current value on the cache line.
An internal store will also search for the given address to see if it present in the cache, but will in the case of a cache miss push a read action to the deque to fetch the current address before writing to it --- write-allocate policy.
Both the internal load and internal store will put the needed action on the bus if the bus is not occupied and it is required by the state transition.


\subsubsection{Bus}

The bus keeps track of the current task on the bus. There can only be one such task at one time. A task has the following form:

\begin{lstlisting}
Task {
    issuer_id: usize,
    remaining_cycles: usize,
    action: BusAction,
}
\end{lstlisting}

Thus, the task contains the id of the core that issued the task, the remaining clock cycles until the task is finished and the type of bus action.
There are a couple of bus actions which are shared between both protocols.
That is, a bus action like \texttt{BusUpdShared} is only valid for the Dragon protocol, so when the MESI protocol is used, this action is ignored.
The bus actions are represented in the following form:

\begin{lstlisting}
BusAction {
    BusRdMem(address, n_bytes),
    BusRdShared(address, n_bytes),
    BusRdXMem(address, n_bytes),
    BusRdXShared(address, n_bytes),
    BusUpdMem(address, n_bytes),
    BusUpdShared(address, n_bytes),
    Flush(address, n_bytes),
}
\end{lstlisting}

Each bus action state contains an address and the number of bytes used for the bus exchange.
Each update cycle the bus proceeds to advance the bus transaction if there is one.

\subsubsection{Protocol}
The protocol is implemented as a trait, where a trait defines shared behaviour.
This is very similar to how interfaces work in other languages than Rust, with some minor differences.
For example, traits cannot have fields.
The shared behaviour for protocol trait is defined like:

\begin{lstlisting}
read()
write()
snoop()
after_snoop()
writeback_required()
invalidate()
is_shared()
\end{lstlisting}
These operations are required for the implementation of the MESI protocol and the Dragon protocol.
As briefly described earlier in the cache section, the cache keeps track of the current protocol in use.
When the cache is doing operations on specific cache lines, it invokes the proper method for the underlying protocol as defined in the trait.
Thus, the protocol is stored like
\begin{lstlisting}
protocol: Box<dyn Protocol>
\end{lstlisting}
and operations are for example invoked like
\begin{lstlisting}
protocol.snoop(...)
\end{lstlisting}

This is really useful as the cache does not need to know which protocol is used, but relying on the fact that the underlying protocol has some defined behaviour for the invoked operation.



\subsection{Protocol}

\subsubsection{MESI}

\begin{figure}[ht]
    \centering
    \incfig{mesi}
    \caption{mesi}
    \label{fig:mesi}
\end{figure}

\subsubsection{Dragon}

\subsection{Advanced Task}
